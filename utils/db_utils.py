import json
import pymysql
from utils.sql_builder import build_metadata_query
from utils.md_utils import write_markdown_document


def execute_query(host, port, username, password, sql):
    """æ‰§è¡Œ SQL å¹¶è¿”å›ç»“æœ"""
    try:
        conn = pymysql.connect(
            host=host, port=port, user=username, password=password,
            charset="utf8mb4", autocommit=True
        )
        cursor = conn.cursor()
        cursor.execute(sql)
        rows = cursor.fetchall()
        cursor.close()
        conn.close()
        return rows
    except Exception as e:
        print(f"âŒ SQLæ‰§è¡Œé”™è¯¯: {e}\nSQL: {sql}")
        return []


def get_metadata(host, port, username, password, sql):
    """æ‰§è¡Œå…ƒæ•°æ®æŸ¥è¯¢å¹¶è¿”å› sha256 åˆ—è¡¨"""
    rows = execute_query(host, port, username, password, sql)
    sha256_list, metadata_map = [], {}
    for row in rows:
        sha256, category, title, author, abstract = row
        sha256_list.append(sha256)
        metadata_map[sha256] = {"title": title, "abstract": abstract}
    return sha256_list, metadata_map


def query_content_batches(host, port, username, password, sha256_list, metadata_map, root_dir, batch_size=500):
    """
    åˆ†æ‰¹æŸ¥è¯¢æ¯ä¸ª sha256 å¯¹åº”çš„å†…å®¹åˆ—è¡¨ï¼Œå¹¶ç”Ÿæˆ Markdown
    ç»Ÿè®¡ï¼šå†…å®¹ä¸ºç©ºï¼ˆè§£æå¤±è´¥ï¼‰ä¸å†…å®¹ç¼ºå¤±ï¼ˆæœªè¿”å›ï¼‰çš„æ–‡æ¡£æ•°é‡
    """
    if not sha256_list:
        print("âŒ sha256åˆ—è¡¨ä¸ºç©ºï¼Œæ— æ³•æŸ¥è¯¢å†…å®¹")
        return 0, 0, 0

    def chunk_list(items, size):
        for i in range(0, len(items), size):
            yield items[i:i + size]

    total_written, empty_count, missing_count = 0, 0, 0
    total = len(sha256_list)
    print(f"ğŸ” å‡†å¤‡æŸ¥è¯¢ {total} æ¡è®°å½•ï¼Œæ‰¹é‡å¤§å° {batch_size}")

    for batch_no, batch in enumerate(chunk_list(sha256_list, batch_size), start=1):
        # ä½¿ç”¨ build_metadata_query ç”Ÿæˆæ‰¹é‡ sha256 æ¡ä»¶
        sql = f"""
        SELECT sha256, content_list
        FROM ads.ads_xinghe_library_content_list_acc_view
        WHERE sha256 IN ('{"', '".join(batch)}')
        """
        rows = execute_query(host, port, username, password, sql)

        found_sha = {r[0] for r in rows}
        batch_missing = set(batch) - found_sha
        missing_count += len(batch_missing)
        for sha in batch_missing:
            title = metadata_map.get(sha, {}).get("title")
            print(f"âš ï¸ ç¼ºå¤±å†…å®¹: {sha} ({title or 'æ— æ ‡é¢˜'})")

        for sha256, content_list in rows:
            title = metadata_map.get(sha256, {}).get("title")
            try:
                parsed = json.loads(content_list) if content_list else []
            except Exception:
                parsed = []

            if not parsed:
                empty_count += 1
                print(f"âš ï¸ ç©ºå†…å®¹è·³è¿‡: {sha256} ({title or 'æ— æ ‡é¢˜'})")
                continue

            # print(parsed)
            # ç¡®ä¿ä¸ºåˆ—è¡¨å¹¶æŒ‰ record_id æ’åº
            if not isinstance(parsed, list):
                parsed = [parsed]
            parsed.sort(key=lambda x: x.get("record_id", 0))

            # å†™å…¥ Markdown
            write_markdown_document(root_dir, sha256, title, parsed)
            total_written += 1

    print(f"\nğŸ“Š æ±‡æ€»ï¼šç”Ÿæˆ {total_written} ç¯‡ï¼Œç©ºå†…å®¹ {empty_count} ç¯‡ï¼Œç¼ºå¤± {missing_count} ç¯‡")
    return total_written, empty_count, missing_count

